Truth-aligned recursive reasoning with guardrails, evidence tiers, and loop control.

> Build agents that “propose & test,” cite evidence, and avoid runaway recursion.



Why this exists

Nudge models toward truth + mercy instead of zealotry or certainty theater.

Make reasoning auditable: claims carry evidence, loops are bounded, contradictions are surfaced.


Features

Recursion Guard — checkpoints, loop limits, contradiction nudges.

Evidence Mode — label claims: {Scripture | Primary | Secondary | Heuristic}.

Agent Modes — Builder, Counselor, Researcher, Critic (hot-swappable).

Boundaries — anti-coercion, zealotry filter, mercy-first handler for distress.

Pipelines — small, composable steps you can unit-test.

Heuristic Core — RF v2 scorer blending fidelity, creativity, flow, and safety.



---

Getting started (current state = local demo)

Note: until we wire a real LLM, the demo stubs the model call and shows how evidence, guardrails, and scoring are threaded. It’s a template you can drop into notebooks/services.




---

LogOS Proto-Heuristic Core (RF v2)

Output to score: 
Target:  (expert rating, downstream lift)
Activation:  or identity

Contributing

Keep modules pure & testable.

Prefer small functions with docstrings and unit tests.

Add one end-to-end example per new mode or guard.


Roadmap (short)

Plug a real LLM call (OpenRouter/OpenAI/etc.) behind an interface.

Add Counselor compassionate-safety mode.

Export full component traces for RF(x).


License

MIT (ship mercy, not coercion).